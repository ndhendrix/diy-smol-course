{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0abf5b62c59b4093bbae6fc8060f1cda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# #| label: auth\n",
        "# # Authenticate to Hugging Face\n",
        "# from huggingface_hub import login\n",
        "\n",
        "# login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from trl import setup_chat_format\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SmolLM2 Chat Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "\n",
        "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define messages for SmolLM2\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"I'm doing well, thank you! How can I assist you today?\",\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Apply chat template without tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conversation with template: <|im_start|>user\n",
            "Hello, how are you?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I'm doing well, thank you! How can I assist you today?<|im_end|>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "\n",
        "print(\"Conversation with template:\", input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conversation decoded: <|im_start|>user\n",
            "Hello, how are you?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I'm doing well, thank you! How can I assist you today?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# add_generation_prompt adds the \"assistant\" role to the end of the conversation\n",
        "input_text = tokenizer.apply_chat_template(\n",
        "    messages, tokenize=True, add_generation_prompt=True\n",
        ")\n",
        "\n",
        "print(\"Conversation decoded:\", tokenizer.decode(token_ids=input_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conversation tokenized: [1, 4093, 198, 19556, 28, 638, 359, 346, 47, 2, 198, 1, 520, 9531, 198, 57, 5248, 2567, 876, 28, 9984, 346, 17, 1073, 416, 339, 4237, 346, 1834, 47, 2, 198, 1, 520, 9531, 198]\n"
          ]
        }
      ],
      "source": [
        "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
        "\n",
        "print(\"Conversation tokenized:\", input_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise: Convert datasets into appropriate format for supervised fine tuning (SFT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/34/5dpg977s4kxb090pdr6t9vbr0000gp/T/ipykernel_38026/4068687702.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython.display\n",
            "  from IPython.core.display import display, HTML\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<iframe\n",
              "  src=\"https://huggingface.co/datasets/HuggingFaceTB/smoltalk/embed/viewer/all/train?row=0\"\n",
              "  frameborder=\"0\"\n",
              "  width=\"100%\"\n",
              "  height=\"360px\"\n",
              "></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "\n",
        "display(\n",
        "    HTML(\n",
        "        \"\"\"<iframe\n",
        "  src=\"https://huggingface.co/datasets/HuggingFaceTB/smoltalk/embed/viewer/all/train?row=0\"\n",
        "  frameborder=\"0\"\n",
        "  width=\"100%\"\n",
        "  height=\"360px\"\n",
        "></iframe>\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03c486dc67a6471c9e01524b06b9bd3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/9.72k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e1f28200b474e3f875f46ec5ccf1b55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/946k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01edc25e2c53449f9369fa4ad89d401f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/52.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff4aee04ead64615915e1a1d4b92537b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/2260 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc780e1d90db49a8837be8a8a34555b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/119 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"HuggingFaceTB/smoltalk\", \"everyday-conversations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'content': 'Hello! How can I help you today?', 'role': 'assistant'}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds['train'][0]['messages'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"<|im_start|>user\\nHi there<|im_end|>\\n<|im_start|>assistant\\nHello! How can I help you today?<|im_end|>\\n<|im_start|>user\\nI'm looking for a beach resort for my next vacation. Can you recommend some popular ones?<|im_end|>\\n<|im_start|>assistant\\nSome popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.<|im_end|>\\n<|im_start|>user\\nThat sounds great. Are there any resorts in the Caribbean that are good for families?<|im_end|>\\n<|im_start|>assistant\\nYes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.<|im_end|>\\n<|im_start|>user\\nOkay, I'll look into those. Thanks for the recommendations!<|im_end|>\\n<|im_start|>assistant\\nYou're welcome. I hope you find the perfect resort for your vacation.<|im_end|>\\n<|im_start|>assistant\\n\""
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.apply_chat_template(ds['train'][0]['messages'], tokenize=False, add_generation_prompt=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40eae1820c72478282fb693ea04a8731",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2260 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd7dd4283c8f4a77b6914831e7584af7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/119 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def process_dataset(sample):\n",
        "    # TODO: 🐢 Convert the sample into a chat format\n",
        "    # use the tokenizer's method to apply the chat template\n",
        "    sample['chatml'] = tokenizer.apply_chat_template(sample['messages'], tokenize=False, add_generation_prompt=True)\n",
        "    return sample\n",
        "\n",
        "ds = ds.map(process_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'full_topic': 'Travel/Vacation destinations/Beach resorts',\n",
              " 'messages': [{'content': 'Hi there', 'role': 'user'},\n",
              "  {'content': 'Hello! How can I help you today?', 'role': 'assistant'},\n",
              "  {'content': \"I'm looking for a beach resort for my next vacation. Can you recommend some popular ones?\",\n",
              "   'role': 'user'},\n",
              "  {'content': \"Some popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.\",\n",
              "   'role': 'assistant'},\n",
              "  {'content': 'That sounds great. Are there any resorts in the Caribbean that are good for families?',\n",
              "   'role': 'user'},\n",
              "  {'content': 'Yes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.',\n",
              "   'role': 'assistant'},\n",
              "  {'content': \"Okay, I'll look into those. Thanks for the recommendations!\",\n",
              "   'role': 'user'},\n",
              "  {'content': \"You're welcome. I hope you find the perfect resort for your vacation.\",\n",
              "   'role': 'assistant'}],\n",
              " 'chatml': \"<|im_start|>user\\nHi there<|im_end|>\\n<|im_start|>assistant\\nHello! How can I help you today?<|im_end|>\\n<|im_start|>user\\nI'm looking for a beach resort for my next vacation. Can you recommend some popular ones?<|im_end|>\\n<|im_start|>assistant\\nSome popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.<|im_end|>\\n<|im_start|>user\\nThat sounds great. Are there any resorts in the Caribbean that are good for families?<|im_end|>\\n<|im_start|>assistant\\nYes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.<|im_end|>\\n<|im_start|>user\\nOkay, I'll look into those. Thanks for the recommendations!<|im_end|>\\n<|im_start|>assistant\\nYou're welcome. I hope you find the perfect resort for your vacation.<|im_end|>\\n<|im_start|>assistant\\n\"}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe\n",
              "  src=\"https://huggingface.co/datasets/openai/gsm8k/embed/viewer/main/train\"\n",
              "  frameborder=\"0\"\n",
              "  width=\"100%\"\n",
              "  height=\"360px\"\n",
              "></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(\n",
        "    HTML(\n",
        "        \"\"\"<iframe\n",
        "  src=\"https://huggingface.co/datasets/openai/gsm8k/embed/viewer/main/train\"\n",
        "  frameborder=\"0\"\n",
        "  width=\"100%\"\n",
        "  height=\"360px\"\n",
        "></iframe>\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define messages for gsm8k\n",
        "messages = [\n",
        "    {\"role\": \"question\", \"content\": \"Hello, how are you?\"},\n",
        "    {\n",
        "        \"role\": \"answer\",\n",
        "        \"content\": \"I'm doing well, thank you! How can I assist you today?\",\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "182827db19a343ad8fadff0e66d42c42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/7.94k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95795c2fdcd24929864d1a973826f184",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dabb11277c144765a6c9238a1e793a59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fac9cdb39544d3dbd6cbd3f93c65ec4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "217955ec04cf496bbdc757a4a842f3da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74544819a3f9426ca6a4650a78991ac2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5b86278a2d945f6a43c765291495466",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1319 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ds = load_dataset(\"openai/gsm8k\", \"main\")\n",
        "\n",
        "\n",
        "def process_dataset(sample):\n",
        "    # TODO: 🐕 Convert the sample into a chat format\n",
        "\n",
        "    # 1. create a message format with the role and content\n",
        "\n",
        "    # 2. apply the chat template to the samples using the tokenizer's method\n",
        "    temp = [\n",
        "        {\"role\": \"question\", \"content\": sample['question']},\n",
        "        {\"role\": \"answer\", \"content\": sample['answer']},\n",
        "    ]\n",
        "\n",
        "    sample['chatml'] = tokenizer.apply_chat_template(temp, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "    return sample\n",
        "\n",
        "\n",
        "ds = ds.map(process_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<|im_start|>question\\nNatalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?<|im_end|>\\n<|im_start|>answer\\nNatalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72<|im_end|>\\n<|im_start|>assistant\\n'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds['train']['chatml'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "diy-smol-course",
      "language": "python",
      "name": ".venv",
      "path": "/Users/nathanielhendrix/Library/Mobile Documents/com~apple~CloudDocs/Documents/Learning/diy-smol-course/.venv/share/jupyter/kernels/python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
